{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreabenevenut/LLM_workshop/blob/main/notebooks/2_Parsing_structured_information_via_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b84edb4e",
      "metadata": {
        "id": "b84edb4e"
      },
      "source": [
        "# LLM Output Parsers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the compelling use cases that demonstrate the power of Large Language models is their capability to efficiently extract pertinent information from text and subsequently parse it into structured formats.\n",
        "\n",
        "Textual data comes in various forms: articles, research papers, social media posts, and moreâ€”often containing critical insights that are buried within the unstructured content. Extracting this information manually can be time-consuming and error-prone. Here's where language models equipped with natural language understanding and processing capabilities can play an important role."
      ],
      "metadata": {
        "id": "JJ1Y4qVWvbTT"
      },
      "id": "JJ1Y4qVWvbTT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0: SET UP"
      ],
      "metadata": {
        "id": "8-mi3R-LuEa5"
      },
      "id": "8-mi3R-LuEa5"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/andreabenevenut/LLM_workshop"
      ],
      "metadata": {
        "id": "QALto4D3jtQ0"
      },
      "execution_count": null,
      "outputs": [],
      "id": "QALto4D3jtQ0"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r \"/content/LLM_workshop/requirements.txt\""
      ],
      "metadata": {
        "id": "V-2m5k6k-eWz"
      },
      "execution_count": null,
      "outputs": [],
      "id": "V-2m5k6k-eWz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCGVD-Nl-D1-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "id": "fCGVD-Nl-D1-"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.indexes.vectorstore import VectorstoreIndexCreator"
      ],
      "metadata": {
        "id": "TfWhpnGo-T85"
      },
      "execution_count": null,
      "outputs": [],
      "id": "TfWhpnGo-T85"
    },
    {
      "cell_type": "markdown",
      "id": "25d89f21",
      "metadata": {
        "id": "25d89f21"
      },
      "source": [
        "# 1: JSON Output Parser\n",
        "Suppose that we have a piec of text and we want to extract information from it in a specific format.\n",
        "\n",
        "One of the most popular formats is JSON.\n",
        "\n",
        "To that, we simply need one to specify the desired output schema and make use of one of the models that langchain provides to interact with LLMs."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_extraction_chain\n",
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "l5XS1jdy0kuF"
      },
      "id": "l5XS1jdy0kuF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"\"\"\n",
        "  Alex (25 years old) is 1.83 meters tall and loves playing basketball. He comes from Orlando and has quite a big family (5 siblings). He has a red Audi and works in the financial sector.\n",
        "\n",
        "  His friend, Claudia, is one year younger than him and has the passion for travelling. She has a dog named Nellie and owns a green BMW. Claudia is very outgoing, sporty and has a good sense of humor.\n",
        "\n",
        "  Ben, Claudia's dad, is 63 and is into peotry and music.\n",
        "  His sophisticated silver Volvo S90 gleams in the driveway, reflecting his appreciation for elegance and refinement. He worked as a librarian for almost 40 years at the local school in town.\n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "yglOpcvvtyoE"
      },
      "id": "yglOpcvvtyoE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e017ba0",
      "metadata": {
        "id": "3e017ba0"
      },
      "outputs": [],
      "source": [
        "# LLM\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# Schema\n",
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"name\": {\"type\": \"string\"},\n",
        "        \"hobby\": {\"type\": \"string\"},\n",
        "        \"age\": {\"type\": \"integer\"},\n",
        "    },\n",
        "    \"required\": [\"name\", \"age\"],\n",
        "}\n",
        "\n",
        "# Extraction chain\n",
        "chain = create_extraction_chain(schema, llm)\n",
        "\n",
        "chain.run(sample_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain"
      ],
      "metadata": {
        "id": "wJfN0U8E145W"
      },
      "id": "wJfN0U8E145W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "dcb03138",
      "metadata": {
        "id": "dcb03138"
      },
      "source": [
        "### Multiple entity types\n",
        "\n",
        "It is also possible to define multiple entities and require our LLM to extract information about each entity separately. To do that, we can make use of prefixes that will indicate the entity name.\n",
        "\n",
        "Suppose that we want to differentiate between people and cars.\n",
        "\n",
        "We can add `person_` and `car_` prefixes for each property"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01eae733",
      "metadata": {
        "id": "01eae733"
      },
      "outputs": [],
      "source": [
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"person_name\": {\"type\": \"string\"},\n",
        "        \"person_hobby\": {\"type\": \"string\"},\n",
        "        \"person_age\": {\"type\": \"integer\"},\n",
        "        \"car_model\": {\"type\": \"string\"},\n",
        "        \"car_color\": {\"type\": \"string\"},\n",
        "    },\n",
        "    \"required\": [\"person_name\", \"person_age\", \"car_model\"],\n",
        "}\n",
        "\n",
        "chain = create_extraction_chain(schema, llm)\n",
        "\n",
        "chain.run(sample_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34f3b958",
      "metadata": {
        "id": "34f3b958"
      },
      "source": [
        "### Extra information\n",
        "\n",
        "The power of functions (relative to using parsers alone) lies in the ability to perform semantic extraction.\n",
        "\n",
        "In particular, `we can ask for things that are not explicitly enumerated in the schema`.\n",
        "\n",
        "Suppose we want unspecified additional information about dogs.\n",
        "\n",
        "We can use add a placeholder for unstructured extraction, `dog_extra_info`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40c7b26f",
      "metadata": {
        "id": "40c7b26f"
      },
      "outputs": [],
      "source": [
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"person_name\": {\"type\": \"string\"},\n",
        "        \"person_hobby\": {\"type\": \"string\"},\n",
        "        \"person_age\": {\"type\": \"integer\"},\n",
        "        \"person_family\": {\"type\": \"string\"},\n",
        "        \"person_dog\": {\"type\": \"string\"},\n",
        "        \"car_model\": {\"type\": \"string\"},\n",
        "        \"car_color\": {\"type\": \"string\"},\n",
        "    },\n",
        "    \"required\": [\"person_name\", \"person_age\", \"car_model\"],\n",
        "}\n",
        "\n",
        "chain = create_extraction_chain(schema, llm)\n",
        "\n",
        "output = chain.run(sample_text)\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(output)\n",
        "df"
      ],
      "metadata": {
        "id": "G7PnyEIDvCMd"
      },
      "id": "G7PnyEIDvCMd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bf71ddce",
      "metadata": {
        "id": "bf71ddce"
      },
      "source": [
        "### Pydantic\n",
        "\n",
        "Pydantic is a data validation and settings management library for Python.\n",
        "\n",
        "It allows you to create data classes with attributes that are automatically validated when you instantiate an object.\n",
        "\n",
        "Lets define a class with attributes annotated with types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d36a743b",
      "metadata": {
        "id": "d36a743b"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, List\n",
        "from langchain.chains import create_extraction_chain_pydantic\n",
        "from langchain.pydantic_v1 import BaseModel\n",
        "\n",
        "# Pydantic data class\n",
        "class Properties(BaseModel):\n",
        "    person_name: str\n",
        "    person_hobby: List[str]\n",
        "    person_age: int\n",
        "    person_family: Optional[str]\n",
        "    person_dog: Optional[str]\n",
        "    car_model: Optional[str]\n",
        "    car_color: Optional[str]\n",
        "\n",
        "# Extraction\n",
        "chain = create_extraction_chain_pydantic(pydantic_schema=Properties, llm=llm, verbose=True)\n",
        "\n",
        "# Run\n",
        "output = chain.run(sample_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "id": "X75Gw9adwjIR"
      },
      "id": "X75Gw9adwjIR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame([vars(obj) for obj in output])\n",
        "df"
      ],
      "metadata": {
        "id": "rfNiSOIPw0Fc"
      },
      "id": "rfNiSOIPw0Fc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cbd9f121",
      "metadata": {
        "id": "cbd9f121"
      },
      "source": [
        "## Format instructions for a chain\n",
        "\n",
        "[Output parsers](/docs/modules/model_io/output_parsers/) are classes that help structure language model responses.\n",
        "\n",
        "As shown above, they are used to parse the output of the OpenAI function calls in `create_extraction_chain`.\n",
        "\n",
        "But, they can be used independent of functions.\n",
        "\n",
        "### Pydantic\n",
        "\n",
        "Just as a above, let's parse a generation based on a Pydantic data class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64650362",
      "metadata": {
        "id": "64650362"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field, validator\n",
        "from typing import Sequence\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(temperature=1, model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# Define your desired data structure.\n",
        "class PetInfo(BaseModel):\n",
        "    pet_name: str = Field(description=\"This is the name of the pet\")\n",
        "    reasoning: str = Field(description=\"This is the reasons for the score\")\n",
        "    likelihood_of_success: int = Field(description=\"This is an integer score between 1-10\")\n",
        "\n",
        "    # You can add custom validation logic easily with Pydantic.\n",
        "    @validator('likelihood_of_success')\n",
        "    def check_score(cls, field):\n",
        "        if field >10:\n",
        "            raise ValueError(\"Badly formed Score\")\n",
        "        return field\n",
        "\n",
        "\n",
        "class PetNames(BaseModel):\n",
        "    pet_names: Sequence[PetInfo] = Field(..., description=\"The pet names\")\n",
        "\n",
        "\n",
        "# Set up a parser + inject instructions into the prompt template.\n",
        "pydantic_parser = PydanticOutputParser(pydantic_object=PetNames)\n",
        "\n",
        "format_instructions = pydantic_parser.get_format_instructions()\n",
        "\n",
        "\n",
        "my_prompt = PromptTemplate(\n",
        "    input_variables = [\"pet_description\", \"format_instructions\"],\n",
        "    template = \"\"\"\n",
        "    You are a wizard at inventing adorable and hilarious names for pets!\n",
        "    Your talent lies in crafting names that are both charming and amusing.\n",
        "    Take the pet's description below, enclosed by triple backticks, and use it as inspiration to create 4 awesome names for the pet.\n",
        "\n",
        "    pet description: ```{pet_description}```\n",
        "\n",
        "    After crafting the new pet names, rate their potential success on a scale of 1 to 10 based on how catchy and memorable they are!\n",
        "\n",
        "    {format_instructions}\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "pet_chain = LLMChain(llm=llm, prompt=my_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = pet_chain({\"pet_description\": \"My cat is 10 years old, it is quite grumpy if I do not give him food, sleeps a lot. He has a gray hair and blue eyes.\",\n",
        "                    \"format_instructions\": format_instructions})\n",
        "output = answer['text']\n",
        "parsed_output = pydantic_parser.parse(output)\n",
        "parsed_output"
      ],
      "metadata": {
        "id": "D4f-y82HNbNL"
      },
      "id": "D4f-y82HNbNL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame([dict(obj) for obj in parsed_output.pet_names])\n",
        "df\n"
      ],
      "metadata": {
        "id": "kPgA19BcOP04"
      },
      "id": "kPgA19BcOP04",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXERCISE"
      ],
      "metadata": {
        "id": "-ulbixEKiQ3K"
      },
      "id": "-ulbixEKiQ3K"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vWSLQF3LjsTv"
      },
      "id": "vWSLQF3LjsTv",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8-mi3R-LuEa5",
        "25d89f21"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}