{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8-mi3R-LuEa5",
        "5CBqNUL_qLlG",
        "3RBifm-DDi6T",
        "JErNbeauJjML"
      ],
      "authorship_tag": "ABX9TyOx+i536x+MklRwzJ+2VoAI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreabenevenut/LLM_workshop/blob/main/notebooks/1_First_interaction_with_LLMs_via_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OUR FIRST INTERACTION WITH LARGE LANGUAGE MODELS\n",
        "\n",
        "This notebook provides an introductory exploration of Large Language Models (LLMs), showcasing how to interact with them using specific inputs to generate text, conduct diverse language tasks, and leverage the advanced capabilities of state-of-the-art language understanding.\n",
        "\n",
        "While employing a single LLM is enough for basic applications, more intricate tasks often necessitate chaining LLMs. Such chaining involves linking LLMs either with one another or with additional components.\n",
        "\n",
        "That is where the Python library [LangChain](https://www.langchain.com/) comes in handy. LangChain is an application framework designed to leverage language models' power.\n",
        "One of the most important components of such library is the so called \"chain\".\n",
        "A chain refers to a sequence of interconnected components designed to accomplish a particular task. This sequence dictates the flow of data and tasks within the AI system.\n",
        "\n",
        "For instance, a simple chain could comprise the following components:\n",
        "\n",
        "User Input ➡️ Large Language Model ➡️ Output Formatter"
      ],
      "metadata": {
        "id": "2NCTte9wmkHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0: Set up"
      ],
      "metadata": {
        "id": "8-mi3R-LuEa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/andreabenevenut/LLM_workshop"
      ],
      "metadata": {
        "id": "QALto4D3jtQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r \"/content/LLM_workshop/requirements.txt\""
      ],
      "metadata": {
        "id": "2-7WKnHep9wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LD91ZkHWp9wc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.indexes.vectorstore import VectorstoreIndexCreator"
      ],
      "metadata": {
        "id": "88fZzPxXp9wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1: First API call to use LLMs"
      ],
      "metadata": {
        "id": "5CBqNUL_qLlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=1)"
      ],
      "metadata": {
        "id": "TfWhpnGo-T85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "I have a cat and I would like to have a cool name for it, related to summer.\n",
        "Suggest me 5 cool names for my pet.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "B1IjEdeF-xIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm(query))"
      ],
      "metadata": {
        "id": "b48cutKn_WlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2: Prompt engineering via templates"
      ],
      "metadata": {
        "id": "3RBifm-DDi6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "pqrny29w_YdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_prompt = PromptTemplate(\n",
        "    input_variables = [\"animal\", \"season\", \"nicknames_numbers\"],\n",
        "    input_types={\n",
        "        \"animal\": str,\n",
        "        \"season\": str,\n",
        "        \"nicknames_numbers\": int\n",
        "        },\n",
        "    template = \"\"\"\n",
        "    I have a {animal} and I would like to have a cool name for it, related to {season}.\n",
        "    Suggest me {nicknames_numbers} cool names for my pet.\n",
        "    \"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "YWMbUmqgDXsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pet_chain = LLMChain(llm=llm, prompt=my_prompt)"
      ],
      "metadata": {
        "id": "SF7vmJndELXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = pet_chain({\"animal\": \"dog\", \"season\": \"winter\", \"nicknames_numbers\": 2})\n",
        "print(answer['text'])"
      ],
      "metadata": {
        "id": "aWyiKEAwFNGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = pet_chain({\"animal\": \"hamster\", \"season\": \"spring\", \"nicknames_numbers\": 10})\n",
        "print(answer['text'])"
      ],
      "metadata": {
        "id": "fGGiHP_wFeC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3: Exercise: Dataroots needs you!"
      ],
      "metadata": {
        "id": "JErNbeauJjML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to help Silke for Dataroots recruitment via social networks. It would be nice to let Silke decide a few variables and then generate results that could help her create the best Instagram or Linkedin post.\n",
        "\n",
        "Use LangChain simple chain, prompt engineering and templates to achieve the task.\n",
        "\n",
        "Imagine that Silke would like to decide:\n",
        "- social_network\n",
        "- tone (e.g. formal or informal)\n",
        "- max number of words\n",
        "- position\n",
        "\n",
        "Be creative and play around to grasp how interactions with LLMs work."
      ],
      "metadata": {
        "id": "Ye0kahLJkSkE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KWJOxzqfNkKj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}